<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><script type="text/javascript" src="http://d3js.org/d3.v3.js" charset="utf-8"></script><script type="text/javascript" src="/javascripts/d3.tip.js"></script><script type="text/javascript" src="/javascripts/columnChart.js"></script><script type="text/javascript" src="http://numericjs.com/numeric/lib/numeric-1.2.6.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/jstat/1.5.2/jstat.min.js"></script><script type="text/javascript" src="https://protobi.com/examples/pca/pca.js"></script><title> Visualizing Neural Networks: A Review of Current Work · Aimee Barciauskas</title><meta name="description" content="Visualizing Neural Networks: A Review of Current Work - Aimee Barciauskas"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="stylesheet" href="/css/apollo.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,600"></head><body><header><a href="/" class="logo-link"><img></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://github.com/abarciauskas-bgse" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="https://www.linkedin.com/in/abarciauskas" target="_blank" class="nav-list-link">LINKEDIN</a></li></ul></header><section class="container"><div class="post"><article class="post-block"><h1 class="post-title">Visualizing Neural Networks: A Review of Current Work</h1><div class="post-time">Apr 17, 2016</div><div class="post-content"><p>Below is a summary of existing efforts to visualize neural networks. I am studying neural networks and their visualizations as my master’s project as a data science master’s candidate.</p>
<p>The rest of this post is organized as follows:</p>
<ul>
<li><a href="#Overview-and-Motivations">Overview and Motivations</a></li>
<li><a href="#Academic-Work">Academic Work</a></li>
<li><a href="#Related-Work">Related Work</a></li>
<li><a href="#Conclusions">Conclusions</a></li>
</ul>
<hr>
<h2 id="Overview-and-Motivations"><a href="#Overview-and-Motivations" class="headerlink" title="Overview and Motivations"></a>Overview and Motivations</h2><p>There are two objectives in visualizing neural networks: to educate and to understand.</p>
<p>Though neural networks have been around for a while, there is little understanding of why and how neural networks work. This has motivated some academic work in visualizing neural networks to understand what’s going on in the different components and levels of neural network architecture and improve performance.</p>
<p>The audience for my master’s project is a general public, with no expected experience in computer science or machine learning. While the work of deep learning practitioners brings one perspective to be inclusive of, it is certainly not the same audience with the same goals.</p>
<p>The motivation in visualizing neural networks for a general public is to educate. My objectives are to provide transparency and satisfy curiousities. Neural networks are being used in many every day applications and those interested should have an opportunity to understand how they work.</p>
<p>I will describe some of the academic approaches and then follow with the approaches which are more educational in nature.</p>
<hr>
<h2 id="Academic-Work"><a href="#Academic-Work" class="headerlink" title="Academic Work"></a>Academic Work</h2><h4 id="Zeiler-and-Fergus-Visualizing-and-Understanding-Convolutional-Networks-2014"><a href="#Zeiler-and-Fergus-Visualizing-and-Understanding-Convolutional-Networks-2014" class="headerlink" title="Zeiler and Fergus, Visualizing and Understanding Convolutional Networks, 2014"></a><a href="https://www.cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf" target="_blank" rel="external">Zeiler and Fergus, Visualizing and Understanding Convolutional Networks, 2014</a></h4><p>What concepts does a neural network learn to be important for image classification? How do concepts develop after intial layers? Visualization of a convolutional network using a deconvolutional network (or <a href="https://www.cs.nyu.edu/~gwtaylor/publications/zeilertaylorfergus_iccv2011.pdf" target="_blank" rel="external">deconvnet</a>) leverages the how a deconvnet maps feature activities back to the original pixel input space. To oversimplify, deconvnets can be used to invert a trained neural network to glean learned concepts and visualize them. I omit the details of the inversion here as it is discussed in detail in their paper.</p>
<p>Zeiler and Fergus produced visualizations using the popularized convnet architectures developed by <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf" target="_blank" rel="external">LeCun et. al.</a> and <a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf" target="_blank" rel="external">Krishevsky et. al.</a>. The visual analysis helped them beat the AlexNet 2012 single-model result by 1.7% using smaller strides (2 vs. 4) and smaller filters (7x7 vs. 11x11).</p>
<h4 id="Jason-Yosinski-DeepVis-2015"><a href="#Jason-Yosinski-DeepVis-2015" class="headerlink" title="Jason Yosinski, DeepVis, 2015"></a><a href="http://yosinski.com/media/papers/Yosinski__2015__ICML_DL__Understanding_Neural_Networks_Through_Deep_Visualization__.pdf" target="_blank" rel="external">Jason Yosinski, DeepVis, 2015</a></h4><p>Jason Yosinski, DeepVis, 2015 published an open source tool, <a href="http://yosinski.com/deepvis" target="_blank" rel="external">DeepVis</a>, for visualizing a neural network in real time, with an image or camera feed. The tool is a dashboard of the network, enabling the user to visualize and interact with intermediary results of the network.</p>
<p>The strength of DeepVis may be in its simplicity. For example, it includes activation plots values which enable the user to see all the data.</p>
<blockquote>
<p>Although this visualization is simple to implement, we find it informative because all data flowing through the network can be visualized. There is nothing mysterious happening behind the scenes. (pg 4)</p>
</blockquote>
<p>Though the features of DeepVis are not innovative themselves, these visualizations yielded new and surprising intuitions:</p>
<ul>
<li>Layers demonstrate locality; that is layers become detectors of different real-world objects like flowers or faces. This suggests that intermediate layers become responsible for different concepts important in a well-trained classifer.</li>
<li>When an image does not include anything from the training set of classes, the real-time probability vector exposed a high sensitivity to small changes in input. In other words, shifting in your chair could mean instead of a cat you are classified a lamp.</li>
<li>Although higher layers are sensitive, lower level computations are robust:</li>
</ul>
<blockquote>
<p>…the network learns to identify these concepts simply because they represent useful partial information for making a later classification decision.</p>
</blockquote>
<p>Yosinski and Zeigler both expressed surprise at finding the features learned by intermediate layers are discernable and important to final classification. This is cool because it suggests the network learns the concepts like text or wheel before it becomes important in classifying books and cars. However, Yonsinski also comments:</p>
<blockquote>
<p>That said, not all features correspond to natural parts, raising the possibility of a different decomposition of the world than humans might expect. These visualizations suggest that further study into the exact nature of learned representations — whether they are local to a single channel or distributed across several — is likely to be interesting. (pg 9)</p>
</blockquote>
<p>The features of the tool and links on how to install it are available here: <a href="http://yosinski.com/deepvis" target="_blank" rel="external">DeepVis</a>.</p>
<hr>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><h4 id="Andrej-Karpathy-Visualizing-what-ConvNets-Learn"><a href="#Andrej-Karpathy-Visualizing-what-ConvNets-Learn" class="headerlink" title="Andrej Karpathy, Visualizing what ConvNets Learn"></a><a href="http://cs231n.github.io/understanding-cnn/" target="_blank" rel="external">Andrej Karpathy, Visualizing what ConvNets Learn</a></h4><p><a href="http://cs231n.github.io/understanding-cnn/" target="_blank" rel="external">Visualizing What Convnets Learn</a> lists and describes useful ways to visualize a variety components of neural networks, including layer activations and visualizing high dimensional feature topologies.</p>
<p>Karpathy also has a cool interactive tool to demonstrate classification by a neural network in 2-dimensions: <a href="cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html">ConvnetJS demo</a>.</p>
<h4 id="Daniel-Smilkov-and-Shan-Carter-A-Neural-Network-Playground-2016"><a href="#Daniel-Smilkov-and-Shan-Carter-A-Neural-Network-Playground-2016" class="headerlink" title="Daniel Smilkov and Shan Carter, A Neural Network Playground, 2016"></a><a href="http://playground.tensorflow.org" target="_blank" rel="external">Daniel Smilkov and Shan Carter, A Neural Network Playground, 2016</a></h4><p>The <a href="http://playground.tensorflow.org" target="_blank" rel="external">Neural Network Playground</a> developed by Daniel Smilkov and Shan Carter offers a user-friendly and attractive interactive tool for understanding at a high level how neural networks work and how you might tune them.</p>
<h4 id="Cristopher-Olah-Neural-Networks-Manifolds-and-Topology-2014"><a href="#Cristopher-Olah-Neural-Networks-Manifolds-and-Topology-2014" class="headerlink" title="Cristopher Olah, Neural Networks, Manifolds, and Topology, 2014"></a><a href="http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/" target="_blank" rel="external">Cristopher Olah, Neural Networks, Manifolds, and Topology, 2014</a></h4><p>Colah and Karpathy both provide helpful animations of how space can be warped such that non-linear data is linearly seperable. One thing I like about Colah’s article in particular is he breaks this down into it’s component parts (weighting, translation and activation function) and provides a visualization of that process in fine-grained detail.</p>
<p>Colah’s intuitive explanations and visualizations of the challenge of warping space such that naturally non-linear data may be linearly seperated. I highly recommend a reading to gain an intuition through simple examples. Colah builds on the intuitions gleaned from this simplified examples to theorize about lower-bounds on the dimensionality requirements of neural networks (i.e. the Manifold Hypothesis).</p>
<p>Colah also has some very good articles on visualizing high-dimensional data, which is relevant but perhaps tangential to this topic:</p>
<ul>
<li><a href="http://colah.github.io/posts/2015-01-Visualizing-Representations/" target="_blank" rel="external">Visualizing Representations: Deep Learning and Human Beings</a></li>
<li><a href="http://colah.github.io/posts/2014-10-Visualizing-MNIST/" target="_blank" rel="external">Visualizing MNIST: An Exploration of Dimensionality Reduction</a></li>
</ul>
<h4 id="Inceptionism-Going-Deeper-into-Neural-Networks"><a href="#Inceptionism-Going-Deeper-into-Neural-Networks" class="headerlink" title="Inceptionism: Going Deeper into Neural Networks"></a><a href="http://googleresearch.blogspot.com.es/2015/06/inceptionism-going-deeper-into-neural.html" target="_blank" rel="external">Inceptionism: Going Deeper into Neural Networks</a></h4><p>Google also “inverts” a trained neural network classifier to compose images from noise, resulting in the well-known inceptionism of a trained neural network which can be used to create continuous surrealist abstractions of an image class. The methodology is, given you have a trained classifier and you want to determine what types of image patterns the classifier has learned, you start with an image of random noise and tweak the image until you get something the classifier finds to be a banana with high probability. This results in the surreal images now identified with Google’s inceptionism idea and help identifiy flaws in a training set.</p>
<hr>
<h2 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h2><ul>
<li>Approaches by academics have been targeted at research interests, and while not directly instructive in creating experiences for a general public, they still offer insight into neural networks: For example, that intermediate layers also may be identifying and isolating important concepts for classification (and thus are more interpretable than originally thought).</li>
<li>There have been few attempts at interactivity and none at gamification as a way to tackle the education objective.</li>
<li>Many of the references including so far are in the domain of image classification, so it will be a thought adventure in how to generalize learnings and approaches into other domains and architectures.</li>
</ul>
</div></article></div></section><footer><div class="paginator"><a href="/2016/04/18/Visualizing-kNN-with-MNIST-Final-DataViz-Project/" class="prev">PRVE</a><a href="/2016/04/14/Stochastic-Modeling-Project/" class="next">NEXT</a></div><div class="copyright"><p>© 2015 - 2016 <a href="abarciauskas-bgse.github.io">Aimee Barciauskas</a>, unless otherwise noted.</p></div></footer><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-65933410-1",'auto');ga('send','pageview');</script><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "//hm.baidu.com/hm.js?a36e15d9e2adec9a21fcdd9f686b1ed2";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script src="https://cdn.bootcss.com/mathjax/2.5.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>