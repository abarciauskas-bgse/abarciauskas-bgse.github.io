<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><script type="text/javascript" src="http://d3js.org/d3.v3.js" charset="utf-8"></script><script type="text/javascript" src="/javascripts/d3.tip.js"></script><script type="text/javascript" src="/javascripts/columnChart.js"></script><script type="text/javascript" src="http://numericjs.com/numeric/lib/numeric-1.2.6.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/jstat/1.5.2/jstat.min.js"></script><script type="text/javascript" src="https://protobi.com/examples/pca/pca.js"></script><title> Measuring Redundancy in Text Corpora: A Review of Current Methods · Aimee Barciauskas</title><meta name="description" content="Measuring Redundancy in Text Corpora: A Review of Current Methods - Aimee Barciauskas"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="stylesheet" href="/css/apollo.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,600"></head><body><header><a href="/" class="logo-link"><img></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://github.com/abarciauskas-bgse" target="_blank" class="nav-list-link">GITHUB</a></li></ul></header><section class="container"><div class="post"><article class="post-block"><h1 class="post-title">Measuring Redundancy in Text Corpora: A Review of Current Methods</h1><div class="post-time">Apr 28, 2016</div><div class="post-content"><p><strong>This review and its subsequent efforts are a part of an on-going project to analyse the text of <a href="https://w33.bcn.cat/GasetaMunicipal/Inici" target="_blank" rel="external">Barcelona’s Municipal Gazette</a>.</strong></p>
<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation:"></a>Motivation:</h3><p>E-government initiatives offer unprecedented transparency into government proceedings. But often their size and use of “administrative jargon” creates a barrier to understanding and parsing by the general public. Exploiting redundancy in these texts may facilitate the initiative to provide insight via summarization and visualition of these texts. To start the task of analyzing redundancy, what follows is a review of existing methods.</p>
<p>This is the motivation for evaluating redundancy in the current effort. Additional motivations are included as inspirational:</p>
<blockquote>
<p>Sentence similarity is considered the basis of many natural language tasks such as information retrieval, question answering and text summarization. (<a href="https://www.researchgate.net/publication/294873785_A_Comprehensive_Comparative_Study_of_Word_and_Sentence_Similarity_Measures" target="_blank" rel="external">A Comprehensive Comparative Study of Word and Sentence Similarity Measures</a>)</p>
<p>..redundancy can be exploited to identify important and accurate information for applications such as summarization and question answering (<a href="http://www.mitpressjournals.org/doi/pdf/10.1162/089120105774321091" target="_blank" rel="external">Sentence Fusion for Multidocument News Summarization</a>).</p>
<p>…most applications based on Twitter share the goal of providing tweets that are both informative and diverse… to keep a high level of diversity, redundant tweets should be removed from the set of tweets displayed to the user (<a href="http://www.aclweb.org/anthology/D11-1061.pdf" target="_blank" rel="external">Linguistic Redundancy in Twitter</a>).</p>
<p>…from a computational linguistic point of view, the high redundancy in micro-blogs gives the unprecedented opportunity to study classical tasks … on very large corpora characterized by an original and emerging linguistic style, pervaded with ungrammatical and colloquial expressions, abbreviations, and new linguistic forms  (<a href="http://www.aclweb.org/anthology/D11-1061.pdf" target="_blank" rel="external">Linguistic Redundancy in Twitter</a>).</p>
<p>O’Shea et al. applied text similarity in Conversational Agents, which are computer programs that interact with humans through natural language dialogue (<a href="https://web.cs.dal.ca/~eem/cvWeb/pubs/2012-Aminul-CAI.pdf" target="_blank" rel="external">Text Similarity using Google Tri-grams</a>).</p>
</blockquote>
<h3 id="Assumptions-and-Notation"><a href="#Assumptions-and-Notation" class="headerlink" title="Assumptions and Notation"></a>Assumptions and Notation</h3><ul>
<li><p>The words text and document may be used interchangeably.</p>
</li>
<li><p>In what follows, an assumption is made measures of similarity can be used to measure redundancy, where redundancy is considered as a more strict definition of similarity. For example, “my dog ate my homework” and “my assignment was eaten by a canine” are both similar and redundant, whereas the former is completely similar, in one sense, to “My homework is to write about what my dog ate” but not redundant.</p>
</li>
<li><p>From the point above, it is assumed that from the exploration of similarity measures, a threshold for different measures as what qualifies a sentence as redundant may be gleaned from human experts, that is, some heuristic to be determined.</p>
</li>
<li><p><code>t1</code> and <code>t2</code> signify two separate text (or document) entities and the objective is to determine if <code>t1</code> is redundant with <code>t2</code> (e.g. boolean).</p>
</li>
<li><p>Measurements of similarity (<code>Sim(t1,t2)</code>) may be evaluated at the levels of n-grams, phrases, sentences, paragraphs and anuncios. Only a subset of these levels is considered below, without loss of generality.</p>
</li>
<li><p>The document-term matrix is a matrix of frequency counts of a term <code>i</code> in a document <code>d</code>. The matrix is then V x D dimension, where <code>D</code> is the total number of documents in the corpora and <code>V</code> is total number of unique terms.</p>
</li>
</ul>
<h3 id="Methods-to-Measure-Similarity-and-Redundancy"><a href="#Methods-to-Measure-Similarity-and-Redundancy" class="headerlink" title="Methods to Measure Similarity and Redundancy"></a>Methods to Measure Similarity and Redundancy</h3><p>In the existing literature, measurements of similarity have been separated into <strong>corpus-</strong>, <strong>knowledge-</strong>, and <strong>hybrid-based</strong> methods. Hybrid methods are excluded from the current review.</p>
<p>The practical difference between corpus and knowledge-based methods is the corpus based depends on word frequences from a specific corpus. A restriction on corpus-based methods is they are quite domain-dependent and often do not generalize outside of a given corpus. This could pose a potential problem for the current efforts if required to measure redundancy across e-government initiatives, but this is not a current requirement, so this limitation is acceptable.</p>
<p>All methods listed below are included given their pertinence to the current problem, with the exception of methods listed in <strong>Of Interest</strong>.</p>
<h4 id="Corpus-Based-Word-Similarity"><a href="#Corpus-Based-Word-Similarity" class="headerlink" title="Corpus-Based Word Similarity"></a>Corpus-Based Word Similarity</h4><p>The bag-of-words (BOW) method is often used as a baseline measurement of similarity between documents. Given a document-term matrix, taking the dot product or cosine of the dot-product between two columns (e.g. documents) gives a BOW-based similarity score of those two documents. The same method can be followed for the tf-idf version of this matrix.</p>
<p><a href="https://en.wikipedia.org/wiki/Latent_semantic_analysis" target="_blank" rel="external">Latent Semantic Analysis</a> (LSA) measures the similarity between words using a word-count per document (e.g. words x documents, or transpose of the document-term matrix) matrix and computing the cosine of the dot product between 2 rows. This within-corpus word similarity measure will enrich measurements of similarity when comparing documents in methods for computing sentence-based similarities in what follows.</p>
<h4 id="Knowlege-Based-Word-Similarity"><a href="#Knowlege-Based-Word-Similarity" class="headerlink" title="Knowlege-Based Word Similarity"></a>Knowlege-Based Word Similarity</h4><p>WordNet bag-of-words (WBOW) is a “knowledge-based” version of Latent Semantic Analysis and is frequently used to enrich measurements of similarity in texts. WordNets are human-generated lexicons and thus do not require the pre-computation or corpus-dependency of LSA. WordNets are popular but may be limited in depth. It will be interesting to see what is available for Catalan.</p>
<h4 id="Knowledge-Based-Document-Similarity"><a href="#Knowledge-Based-Document-Similarity" class="headerlink" title="Knowledge-Based Document Similarity"></a>Knowledge-Based Document Similarity</h4><p>Knowledge-based document similarity measures listed in <a href="https://www.researchgate.net/publication/294873785_A_Comprehensive_Comparative_Study_of_Word_and_Sentence_Similarity_Measures" target="_blank" rel="external">Atoum</a> use a knowledge-based measurement of word similarity within a document and some quantification for document structure. For example, measurments composed of <a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=5713120&amp;searchWithin%3Dkernel%26filter%3DAND%28p_IS_Number%3A5713046%29" target="_blank" rel="external">WBOW plus part-of-speech (POS) tree kernels</a> or <a href="http://www.sciencedirect.com/science/article/pii/S0957417410011875?np=y" target="_blank" rel="external">POS tags</a>. Others are listed in <a href="https://www.researchgate.net/publication/294873785_A_Comprehensive_Comparative_Study_of_Word_and_Sentence_Similarity_Measures" target="_blank" rel="external">Atoum Section 2.2.2</a>. Theses methods demonstrated poor results or were not evaluated in <a href="https://www.researchgate.net/publication/294873785_A_Comprehensive_Comparative_Study_of_Word_and_Sentence_Similarity_Measures" target="_blank" rel="external">Atoum</a>, and some of the more attractive versions are not available for review. For these reasons, focus will be on corpus-based methods (and possibly hybrid-based methods later on).</p>
<h4 id="Corpus-Based-Document-Similarity"><a href="#Corpus-Based-Document-Similarity" class="headerlink" title="Corpus-Based Document Similarity"></a>Corpus-Based Document Similarity</h4><p>Corpus-based measures of document similarity rely on string similarity, string edit distance and word orders. Other common methods are the <a href="https://en.wikipedia.org/wiki/Edit_distance" target="_blank" rel="external">edit-distance</a> and <a href="https://en.wikipedia.org/wiki/Smith%E2%80%93Waterman_algorithm" target="_blank" rel="external">Smith-Waterman Alignment</a>. These methods will be used as baselines for more advanced methods, but also may provide valuable insights.</p>
<p>In <a href="https://www.researchgate.net/publication/294873785_A_Comprehensive_Comparative_Study_of_Word_and_Sentence_Similarity_Measures" target="_blank" rel="external">Atoum</a>, the highest-performing method was the <a href="https://web.cs.dal.ca/~eem/cvWeb/pubs/2012-Aminul-CAI.pdf" target="_blank" rel="external">Google Tri-Gram</a> approach. This approach calculates a word-similarity metric using trigrams and then uses it in a subsequent text similarity metric. In essence, this metric evaluates the similarity of word <code>w_a</code> and <code>w_b</code> by measuring the frequency of tri-gram instances containing <code>w_a</code> and <code>w_b</code> in positions 1 and 3 of the trigram.</p>
<p>Tree-based measurments leverage a tree data-structure representation of a document (i.e. sentence). In <a href="http://www.aclweb.org/anthology/D11-1061.pdf" target="_blank" rel="external">Linguistic Redundancy in Twitter</a> the most successful formulation was a combination metric using WBOW and the Syntatic First-Order Rule Content Model (FOR). The FOR feature space introduced by <a href="http://www.aclweb.org/anthology/P06-1051" target="_blank" rel="external">Zanzotto and Moschitti</a> constructs features as a pair of syntatic tree fragments augmented with variables which are evaluated for similarity.</p>
<p><a href="http://www.mitpressjournals.org/doi/pdf/10.1162/089120105774321091" target="_blank" rel="external">Simfinder</a> also uses sentence syntax trees to compte sentence similarity, without expectation on their complate alignment.</p>
<h2 id="In-conclusion-Overview-of-strategy-for-analysing-redundancy-in-Barcelona’s-Municipal-Gazette"><a href="#In-conclusion-Overview-of-strategy-for-analysing-redundancy-in-Barcelona’s-Municipal-Gazette" class="headerlink" title="In conclusion: Overview of strategy for analysing redundancy in Barcelona’s Municipal Gazette"></a>In conclusion: Overview of strategy for analysing redundancy in Barcelona’s Municipal Gazette</h2><h4 id="Evaluation-of-methods"><a href="#Evaluation-of-methods" class="headerlink" title="Evaluation of methods"></a>Evaluation of methods</h4><p>Due to the preliminary nature of these methods and research, evaluation will be limited to inspection of the researchers, e.g. “sanity” checks that document pairs classified as redundant are reasonable and comparative scoring between methods using the <a href="https://en.wikipedia.org/wiki/F1_score" target="_blank" rel="external">F-measure</a>.</p>
<h4 id="Order-of-work"><a href="#Order-of-work" class="headerlink" title="Order of work"></a>Order of work</h4><ol>
<li>Extract sentences as documents (later on replace sentences with ngrams, phrases, parapgraphs, or anuncios)</li>
<li>Construct BOW and tf-idf document-term matrices</li>
<li>Extract reasonable clusters of documents. These clusters will limit computation required in the following steps to evaluation of within-cluster pairs.</li>
<li>Evaluate similarity between documents using BOW and tf-idf (e.g. cosine similarity of pair-wise rows).</li>
<li>Compute the LSA word-similarity and repeat step 4 weighting counts and tf-idf scores with their LSA similarity score.</li>
<li>If WordNet is accessible for Catalan, repeat step 4 using WordNet similarity.</li>
<li>Compute edit-distance</li>
<li>Compute Smith-Waterman Alignment</li>
<li>Advanced methods will be attempted in the following order: <a href="https://web.cs.dal.ca/~eem/cvWeb/pubs/2012-Aminul-CAI.pdf" target="_blank" rel="external">Google tri-gram</a>, <a href="http://www.mitpressjournals.org/doi/pdf/10.1162/089120105774321091" target="_blank" rel="external">Simfinder</a>, and <a href="http://www.aclweb.org/anthology/D11-1061.pdf" target="_blank" rel="external">WBOW + FOR</a></li>
</ol>
<h4 id="Of-Interest"><a href="#Of-Interest" class="headerlink" title="Of Interest"></a>Of Interest</h4><ul>
<li>In <a href="https://www.researchgate.net/publication/294873785_A_Comprehensive_Comparative_Study_of_Word_and_Sentence_Similarity_Measures" target="_blank" rel="external">Atoum</a>, <a href="https://www.site.uottawa.ca/~diana/publications/tkdd.pdf" target="_blank" rel="external">Semantic Text Similarity Using Corpus-Based Word Similarity and String Similarity</a> is used in the evaluation and the paper is available so this method may be implemented. It has not yet been reviewed which is why it is not featured in the <strong>Corpus-Based Document Similarity</strong> section of this document.</li>
<li><a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0087555" target="_blank" rel="external">RedLDA</a> is redundancy aware topic modelling builds on LDA topic modelling to address the assumption that words are sampled from a topic distribution, where in fact in the case there is redundancy they are copied from another document. It was used to identify copy-paste instances in patient heath records.<ul>
<li>Uses <a href="https://en.wikipedia.org/wiki/Smith%E2%80%93Waterman_algorithm" target="_blank" rel="external">Smith-Waterman Alignment</a> to characterize redundancy.</li>
<li>The online fingerprinting method is used to identify which string are unique within a record.</li>
<li><a href="http://dl.acm.org/citation.cfm?id=944937" target="_blank" rel="external">Latent Dirichlet Allocation</a> is a generative probabilistic model of text corpora.</li>
</ul>
</li>
<li><a href="http://www.jmlr.org/papers/volume5/yu04a/yu04a.pdf" target="_blank" rel="external">Identifying feature redundancy using a Markov blanket</a> (1208), identifies highly correlated features using symmetrical uncertainty (1212), identifies predomininat features (e.g. does not have any approximate Markov blanket in the current set) and then removing all features for which it forms an approximate Markov blanket.</li>
</ul>
</div></article></div></section><footer><div class="paginator"><a href="/2016/05/06/Neuron-Vis-prototype/" class="prev">PRVE</a><a href="/2016/04/24/Visualizing-Neurons-for-a-Neural-Network/" class="next">NEXT</a></div><div class="copyright"><p>© 2015 - 2016 <a href="abarciauskas-bgse.github.io">Aimee Barciauskas</a>, unless otherwise noted.</p></div></footer><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-65933410-1",'auto');ga('send','pageview');</script><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "//hm.baidu.com/hm.js?a36e15d9e2adec9a21fcdd9f686b1ed2";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script src="https://cdn.bootcss.com/mathjax/2.5.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>